{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flexible_validation as fv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_convolve2d_saclesim_config(name: str, C: int, H: int, W: int, K: int, R: int, S: int) -> fv.ValidationConfig:\n",
    "    return fv.ValidationConfig(\n",
    "        name=name,\n",
    "        kernel_type=fv.KernelType.CONVOLVE_SCALESIM,\n",
    "        inputs=[((1, C, H, W), jnp.float16),\n",
    "                ((K, C, R, S), jnp.float16),]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile directory: ./trace3\n"
     ]
    }
   ],
   "source": [
    "import flexible_validation as fv\n",
    "\n",
    "\n",
    "\n",
    "manager = fv.ValidationManager(profile_dir=\"./trace3\")\n",
    "\n",
    "# Add matrix multiplication configurations with different sizes\n",
    "matmul_configs = [\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_64x64\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((64, 64), jnp.float16), ((64, 64), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_256x256\", \n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((256, 256), jnp.float16), ((256, 256), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_1024x1024\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY, \n",
    "        inputs=[((1024, 1024), jnp.float16), ((1024, 1024), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_4096x4096\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((4096, 4096), jnp.float16), ((4096, 4096), jnp.float16)]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add configurations to the manager\n",
    "for config in matmul_configs:\n",
    "    manager.add_config(config)\n",
    "\n",
    "# Add dot product configurations with different sizes\n",
    "dot_product_configs = [\n",
    "    fv.ValidationConfig(\n",
    "        name=\"dot_product_64\",\n",
    "        kernel_type=fv.KernelType.DOT_PRODUCT,\n",
    "        inputs=[((64,), jnp.float16), ((64,), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"dot_product_256\",\n",
    "        kernel_type=fv.KernelType.DOT_PRODUCT,\n",
    "        inputs=[((256,), jnp.float16), ((256,), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"dot_product_1024\",\n",
    "        kernel_type=fv.KernelType.DOT_PRODUCT,\n",
    "        inputs=[((1024,), jnp.float16), ((1024,), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"dot_product_4096\",\n",
    "        kernel_type=fv.KernelType.DOT_PRODUCT,\n",
    "        inputs=[((4096,), jnp.float16), ((4096,), jnp.float16)]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add dot product configurations to the manager\n",
    "for config in dot_product_configs:\n",
    "    manager.add_config(config)\n",
    "\n",
    "\n",
    "# Add matmul-based dot product configurations\n",
    "matmul_dot_product_configs = [\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_dot_product_64\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((1, 64), jnp.float16), ((64, 1), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_dot_product_256\", \n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((1, 256), jnp.float16), ((256, 1), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_dot_product_1024\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY, \n",
    "        inputs=[((1, 1024), jnp.float16), ((1024, 1), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_dot_product_4096\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((1, 4096), jnp.float16), ((4096, 1), jnp.float16)]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add matmul-based dot product configurations to the manager\n",
    "for config in matmul_dot_product_configs:\n",
    "    manager.add_config(config)\n",
    "\n",
    "# Add convolution configurations\n",
    "convolution_configs = [\n",
    "    fv.ValidationConfig(\n",
    "        name=\"convolution_64x64\",\n",
    "        kernel_type=fv.KernelType.CONVOLVE_SCALESIM,\n",
    "        inputs=[((1, 3, 64, 64), jnp.float16), ((32, 3, 3, 3), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"convolution_256x256\",\n",
    "        kernel_type=fv.KernelType.CONVOLVE_SCALESIM,\n",
    "        inputs=[((1, 3, 256, 256), jnp.float16), ((32, 3, 3, 3), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"convolution_1024x1024\",\n",
    "        kernel_type=fv.KernelType.CONVOLVE_SCALESIM,\n",
    "        inputs=[((1, 3, 1024, 1024), jnp.float16), ((32, 3, 3, 3), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"convolution_4096x4096\",\n",
    "        kernel_type=fv.KernelType.CONVOLVE_SCALESIM,\n",
    "        inputs=[((1, 3, 4096, 4096), jnp.float16), ((32, 3, 3, 3), jnp.float16)]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add convolution configurations to the manager\n",
    "for config in convolution_configs:\n",
    "    manager.add_config(config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile directory: ./trace4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 05:37:17.610864: E external/xla/xla/python/profiler/internal/python_hooks.cc:412] Can't import tensorflow.python.profiler.trace\n",
      "2025-07-04 05:37:17.698941: E external/xla/xla/python/profiler/internal/python_hooks.cc:412] Can't import tensorflow.python.profiler.trace\n",
      "2025-07-04 05:37:19.082186: E external/xla/xla/python/profiler/internal/python_hooks.cc:412] Can't import tensorflow.python.profiler.trace\n",
      "2025-07-04 05:37:19.165241: E external/xla/xla/python/profiler/internal/python_hooks.cc:412] Can't import tensorflow.python.profiler.trace\n",
      "2025-07-04 05:37:20.863142: E external/xla/xla/python/profiler/internal/python_hooks.cc:412] Can't import tensorflow.python.profiler.trace\n",
      "2025-07-04 05:37:20.945348: E external/xla/xla/python/profiler/internal/python_hooks.cc:412] Can't import tensorflow.python.profiler.trace\n",
      "2025-07-04 05:37:22.604666: E external/xla/xla/python/profiler/internal/python_hooks.cc:412] Can't import tensorflow.python.profiler.trace\n",
      "2025-07-04 05:37:22.684556: E external/xla/xla/python/profiler/internal/python_hooks.cc:412] Can't import tensorflow.python.profiler.trace\n",
      "2025-07-04 05:37:24.268032: E external/xla/xla/python/profiler/internal/python_hooks.cc:412] Can't import tensorflow.python.profiler.trace\n",
      "2025-07-04 05:37:24.348730: E external/xla/xla/python/profiler/internal/python_hooks.cc:412] Can't import tensorflow.python.profiler.trace\n"
     ]
    }
   ],
   "source": [
    "# Create a new manager for matmul configurations\n",
    "matmul_manager = fv.ValidationManager(profile_dir=\"./trace4\")\n",
    "\n",
    "# Define matmul configurations with the specified dimensions\n",
    "matmul_configs = [\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_8x8\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((8, 8), jnp.float16), ((8, 8), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_32x32\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((32, 32), jnp.float16), ((32, 32), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_128x128\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((128, 128), jnp.float16), ((128, 128), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_512x128\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((512, 128), jnp.float16), ((128, 128), jnp.float16)]\n",
    "    ),\n",
    "    fv.ValidationConfig(\n",
    "        name=\"matmul_2048x128\",\n",
    "        kernel_type=fv.KernelType.MATRIX_MULTIPLY,\n",
    "        inputs=[((2048, 128), jnp.float16), ((128, 128), jnp.float16)]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add matmul configurations to the new manager\n",
    "for config in matmul_configs:\n",
    "    matmul_manager.add_config(config)\n",
    "\n",
    "matmul_manager.profile_all_packages()\n",
    "matmul_manager.parse_all_packages()\n",
    "df = matmul_manager.get_filtered_events_dataframe(save_to_file=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "[(2, 128, 512), (2, 128, 1024), (2, 128, 1536), (2, 128, 2048), (2, 128, 2560), (2, 128, 3072), (2, 128, 3584), (2, 128, 4096), (2, 256, 512), (2, 256, 1024), (2, 256, 1536), (2, 256, 2048), (2, 256, 2560), (2, 256, 3072), (2, 256, 3584), (2, 256, 4096), (2, 384, 512), (2, 384, 1024), (2, 384, 1536), (2, 384, 2048), (2, 384, 2560), (2, 384, 3072), (2, 384, 3584), (2, 384, 4096), (2, 512, 512), (2, 512, 1024), (2, 512, 1536), (2, 512, 2048), (2, 512, 2560), (2, 512, 3072), (2, 512, 3584), (2, 512, 4096), (2, 640, 512), (2, 640, 1024), (2, 640, 1536), (2, 640, 2048), (2, 640, 2560), (2, 640, 3072), (2, 640, 3584), (2, 640, 4096), (2, 768, 512), (2, 768, 1024), (2, 768, 1536), (2, 768, 2048), (2, 768, 2560), (2, 768, 3072), (2, 768, 3584), (2, 768, 4096), (2, 896, 512), (2, 896, 1024), (2, 896, 1536), (2, 896, 2048), (2, 896, 2560), (2, 896, 3072), (2, 896, 3584), (2, 896, 4096), (2, 1024, 512), (2, 1024, 1024), (2, 1024, 1536), (2, 1024, 2048), (2, 1024, 2560), (2, 1024, 3072), (2, 1024, 3584), (2, 1024, 4096), (4, 128, 512), (4, 128, 1024), (4, 128, 1536), (4, 128, 2048), (4, 128, 2560), (4, 128, 3072), (4, 128, 3584), (4, 128, 4096), (4, 256, 512), (4, 256, 1024), (4, 256, 1536), (4, 256, 2048), (4, 256, 2560), (4, 256, 3072), (4, 256, 3584), (4, 256, 4096), (4, 384, 512), (4, 384, 1024), (4, 384, 1536), (4, 384, 2048), (4, 384, 2560), (4, 384, 3072), (4, 384, 3584), (4, 384, 4096), (4, 512, 512), (4, 512, 1024), (4, 512, 1536), (4, 512, 2048), (4, 512, 2560), (4, 512, 3072), (4, 512, 3584), (4, 512, 4096), (4, 640, 512), (4, 640, 1024), (4, 640, 1536), (4, 640, 2048), (4, 640, 2560), (4, 640, 3072), (4, 640, 3584), (4, 640, 4096), (4, 768, 512), (4, 768, 1024), (4, 768, 1536), (4, 768, 2048), (4, 768, 2560), (4, 768, 3072), (4, 768, 3584), (4, 768, 4096), (4, 896, 512), (4, 896, 1024), (4, 896, 1536), (4, 896, 2048), (4, 896, 2560), (4, 896, 3072), (4, 896, 3584), (4, 896, 4096), (4, 1024, 512), (4, 1024, 1024), (4, 1024, 1536), (4, 1024, 2048), (4, 1024, 2560), (4, 1024, 3072), (4, 1024, 3584), (4, 1024, 4096), (6, 128, 512), (6, 128, 1024), (6, 128, 1536), (6, 128, 2048), (6, 128, 2560), (6, 128, 3072), (6, 128, 3584), (6, 128, 4096), (6, 256, 512), (6, 256, 1024), (6, 256, 1536), (6, 256, 2048), (6, 256, 2560), (6, 256, 3072), (6, 256, 3584), (6, 256, 4096), (6, 384, 512), (6, 384, 1024), (6, 384, 1536), (6, 384, 2048), (6, 384, 2560), (6, 384, 3072), (6, 384, 3584), (6, 384, 4096), (6, 512, 512), (6, 512, 1024), (6, 512, 1536), (6, 512, 2048), (6, 512, 2560), (6, 512, 3072), (6, 512, 3584), (6, 512, 4096), (6, 640, 512), (6, 640, 1024), (6, 640, 1536), (6, 640, 2048), (6, 640, 2560), (6, 640, 3072), (6, 640, 3584), (6, 640, 4096), (6, 768, 512), (6, 768, 1024), (6, 768, 1536), (6, 768, 2048), (6, 768, 2560), (6, 768, 3072), (6, 768, 3584), (6, 768, 4096), (6, 896, 512), (6, 896, 1024), (6, 896, 1536), (6, 896, 2048), (6, 896, 2560), (6, 896, 3072), (6, 896, 3584), (6, 896, 4096), (6, 1024, 512), (6, 1024, 1024), (6, 1024, 1536), (6, 1024, 2048), (6, 1024, 2560), (6, 1024, 3072), (6, 1024, 3584), (6, 1024, 4096), (8, 128, 512), (8, 128, 1024), (8, 128, 1536), (8, 128, 2048), (8, 128, 2560), (8, 128, 3072), (8, 128, 3584), (8, 128, 4096), (8, 256, 512), (8, 256, 1024), (8, 256, 1536), (8, 256, 2048), (8, 256, 2560), (8, 256, 3072), (8, 256, 3584), (8, 256, 4096), (8, 384, 512), (8, 384, 1024), (8, 384, 1536), (8, 384, 2048), (8, 384, 2560), (8, 384, 3072), (8, 384, 3584), (8, 384, 4096), (8, 512, 512), (8, 512, 1024), (8, 512, 1536), (8, 512, 2048), (8, 512, 2560), (8, 512, 3072), (8, 512, 3584), (8, 512, 4096), (8, 640, 512), (8, 640, 1024), (8, 640, 1536), (8, 640, 2048), (8, 640, 2560), (8, 640, 3072), (8, 640, 3584), (8, 640, 4096), (8, 768, 512), (8, 768, 1024), (8, 768, 1536), (8, 768, 2048), (8, 768, 2560), (8, 768, 3072), (8, 768, 3584), (8, 768, 4096), (8, 896, 512), (8, 896, 1024), (8, 896, 1536), (8, 896, 2048), (8, 896, 2560), (8, 896, 3072), (8, 896, 3584), (8, 896, 4096), (8, 1024, 512), (8, 1024, 1024), (8, 1024, 1536), (8, 1024, 2048), (8, 1024, 2560), (8, 1024, 3072), (8, 1024, 3584), (8, 1024, 4096), (10, 128, 512), (10, 128, 1024), (10, 128, 1536), (10, 128, 2048), (10, 128, 2560), (10, 128, 3072), (10, 128, 3584), (10, 128, 4096), (10, 256, 512), (10, 256, 1024), (10, 256, 1536), (10, 256, 2048), (10, 256, 2560), (10, 256, 3072), (10, 256, 3584), (10, 256, 4096), (10, 384, 512), (10, 384, 1024), (10, 384, 1536), (10, 384, 2048), (10, 384, 2560), (10, 384, 3072), (10, 384, 3584), (10, 384, 4096), (10, 512, 512), (10, 512, 1024), (10, 512, 1536), (10, 512, 2048), (10, 512, 2560), (10, 512, 3072), (10, 512, 3584), (10, 512, 4096), (10, 640, 512), (10, 640, 1024), (10, 640, 1536), (10, 640, 2048), (10, 640, 2560), (10, 640, 3072), (10, 640, 3584), (10, 640, 4096), (10, 768, 512), (10, 768, 1024), (10, 768, 1536), (10, 768, 2048), (10, 768, 2560), (10, 768, 3072), (10, 768, 3584), (10, 768, 4096), (10, 896, 512), (10, 896, 1024), (10, 896, 1536), (10, 896, 2048), (10, 896, 2560), (10, 896, 3072), (10, 896, 3584), (10, 896, 4096), (10, 1024, 512), (10, 1024, 1024), (10, 1024, 1536), (10, 1024, 2048), (10, 1024, 2560), (10, 1024, 3072), (10, 1024, 3584), (10, 1024, 4096), (12, 128, 512), (12, 128, 1024), (12, 128, 1536), (12, 128, 2048), (12, 128, 2560), (12, 128, 3072), (12, 128, 3584), (12, 128, 4096), (12, 256, 512), (12, 256, 1024), (12, 256, 1536), (12, 256, 2048), (12, 256, 2560), (12, 256, 3072), (12, 256, 3584), (12, 256, 4096), (12, 384, 512), (12, 384, 1024), (12, 384, 1536), (12, 384, 2048), (12, 384, 2560), (12, 384, 3072), (12, 384, 3584), (12, 384, 4096), (12, 512, 512), (12, 512, 1024), (12, 512, 1536), (12, 512, 2048), (12, 512, 2560), (12, 512, 3072), (12, 512, 3584), (12, 512, 4096), (12, 640, 512), (12, 640, 1024), (12, 640, 1536), (12, 640, 2048), (12, 640, 2560), (12, 640, 3072), (12, 640, 3584), (12, 640, 4096), (12, 768, 512), (12, 768, 1024), (12, 768, 1536), (12, 768, 2048), (12, 768, 2560), (12, 768, 3072), (12, 768, 3584), (12, 768, 4096), (12, 896, 512), (12, 896, 1024), (12, 896, 1536), (12, 896, 2048), (12, 896, 2560), (12, 896, 3072), (12, 896, 3584), (12, 896, 4096), (12, 1024, 512), (12, 1024, 1024), (12, 1024, 1536), (12, 1024, 2048), (12, 1024, 2560), (12, 1024, 3072), (12, 1024, 3584), (12, 1024, 4096)]\n"
     ]
    }
   ],
   "source": [
    "shape_list = []\n",
    "# for m in range(8192, 32769, 128):\n",
    "#     shape_list.append((m,))\n",
    "\n",
    "# for m in range(64, 1025, 64):\n",
    "#     for n in range(64, 1025, 64):\n",
    "#         # if m*n > 8192:\n",
    "#         #     continue\n",
    "#         shape_list.append((m, n))\n",
    "\n",
    "\n",
    "# for M in range(512, 1025, 128):\n",
    "#     for N in range(512, 1025, 128):\n",
    "#         for K in range(512, 1025, 128):\n",
    "#             shape_list.append((M, N, K))\n",
    "\n",
    "\n",
    "for N in range(2, 14, 2):\n",
    "    for L in range(128, 1025, 128):\n",
    "        for H in range(512, 4097, 512):\n",
    "            shape_list.append((N, L, H))\n",
    "\n",
    "\n",
    "print(len(shape_list))\n",
    "print(shape_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18396\n",
      "13428\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def scale(m, n, k, systolic_array_size: int = 128):\n",
    "    return (2*systolic_array_size + systolic_array_size + m - 2) * math.ceil(n / systolic_array_size) * math.ceil(k / systolic_array_size)\n",
    "\n",
    "\n",
    "print(scale(129, 742, 737))\n",
    "print(scale(737, 742, 129))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
